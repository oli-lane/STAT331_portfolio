---
title: "STAT 331 Portfolio"
author: "Oliver Lane"
format: 
  html:
    theme: lux 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an **A**.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

Lab 2 Question 1

```{r}
#| label: wd-1-csv
surveys <- read_csv(here::here("data", "surveys.csv"))
```

-   `xlsx`

PA 4 Question 1

```{r}
#| label: wd-1-xlsx
military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = "Share of Govt. spending", 
                      skip  = 7, 
                      n_max = 191)
```

-   `txt`

Check-in 2.3

```{r}
#| label: wd-1-txt
ages_mystery <- read_delim(here::here("Week 2","Check-ins","Ages_Data",
                                      "ages_mystery.txt"), delim = "|")
```

**WD-2: I can select necessary columns from a dataset.**

Lab 3 Question 5

```{r}
#| label: wd-2

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants >= 10) |>
  mutate(teacher_id = as.character(teacher_id)) |>
  select(course_id, teacher_id, question_no, no_participants, resp_share,
         SET_score_avg, percent_failed_cur, academic_degree, seniority, sex)

```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

Lab 3 Question 5

```{r}
#| label: wd-3-numeric

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants >= 10) |>
  mutate(teacher_id = as.character(teacher_id)) |>
  select(course_id, teacher_id, question_no, no_participants, resp_share, SET_score_avg,
         percent_failed_cur, academic_degree, seniority, sex)

```

-   character -- specifically a string (example must use functions from **stringr**)

Lab 5 (revised to use str_starts instead of str_detect as advised in midterm portfolio review. str_start() is more in line with the clue because her first name is Annabel, not her last name)

```{r}
#| label: wd-3-string

person |>
  filter(address_street_name == "Northwestern Dr" & address_number == max(address_number) |
         str_starts(name, "Annabel") & address_street_name == "Franklin Ave") |>
  inner_join(interview, by = join_by(id == person_id)) |>
  pull(transcript)

```

-   factor

Lab 4 Question 2 (Revised to convert state_abbreviation to a factor before filtering as it was originally a string. This is appropriate because
state abbreviations are categorical data and there are only 50 possible values so we can create levels for each, whereas strings can be anything)

```{r}
#| label: wd-3-factor

ca_childcare <- counties |>
  mutate(state_abbreviation = as.factor(state_abbreviation)) |>
  filter(state_abbreviation == "CA") |>
  inner_join(childcare_costs,
             by = "county_fips_code")

```

-   date (example must use functions from **lubridate**)

Lab 5 (revised to include all the suspect information and left join with interviews to see if the final suspect had any additional clues. Also revised to convert date to a date object and check if the date is within the interval from 12/1/2017 - 12/31/2017, which utilizes lubridate functions instead of using strdetect and looking for \^201712. This ensures that the code is resistant to changes in date formatting)

```{r}
#| label: wd-3-date

drivers_license |>
  rename(license_id = id) |>
  filter(gender == "female",
         hair_color == "red",
         car_make == "Tesla",
         car_model == "Model S",
         height >= 65,
         height <= 67) |>
  inner_join(person, by = "license_id") |>
  inner_join(facebook_event_checkin, by = join_by(id == person_id)) |>
  mutate(date = ymd(date)) |>
  filter(
    event_name == "SQL Symphony Concert",
    date %within% interval(ymd("2017-12-01"), ymd("2017-12-31"))
  ) |>
  group_by(name) |>
  filter(n() == 3) |>
  distinct(name, .keep_all = TRUE) |>
  left_join(interview, by = join_by(id == person_id)) |>
  select(name, id, transcript)

```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric (using `as.numeric()` is not sufficient)

Challenge 3 Question 1

```{r}
#| label: wd-4-numeric

teacher_evals_compare <- teacher_evals |>
  filter(question_no == 903) |>
  mutate(
    SET_level = ifelse(SET_score_avg >= 4, "Excellent", "Standard"),
    sen_level = ifelse(seniority <= 4, "Junior", "Senior")
  ) |>
  select(
    course_id,
    SET_level,
    sen_level
)

```

-   character -- specifically a string (example must use functions from **stringr**)

Lab 5 (revised to change Dr to Drive using a stringr function to make the investigation more resistant to different inputs. This way, if the address is entered as Northwestern Drive or Northwestern Dr, I'll still be able to find the witness)

```{r}
#| label: wd-4-string

person |>
  mutate(address_street_name = str_replace(address_street_name, "Dr$", "Drive")) |>
  filter(address_street_name == "Northwestern Drive" & address_number == max(address_number) |
         str_starts(name, "Annabel") & address_street_name == "Franklin Ave") |>
  inner_join(interview, by = join_by(id == person_id)) |>
  pull(transcript)

```

-   factor (example must use functions from **forcats**)

Lab 4 Question 3

```{r}
#| label: wd-4-factor

ca_childcare <- ca_childcare |> 
  mutate(county_name = str_remove(county_name, " County"),
         region = fct_collapse(county_name,
                               "Superior California" = c("Butte", "Colusa", "El Dorado", "Glenn", "Lassen", "Modoc", "Nevada", "Placer", "Plumas", "Sacramento", "Shasta", "Sierra", "Siskiyou", "Sutter", "Tehama", "Yolo", "Yuba"),
                               "North Coast" = c("Del Norte", "Humboldt", "Lake", "Mendocino", "Napa", "Sonoma", "Trinity"),
                               "San Francisco Bay Area" = c("Alameda", "Contra Costa", "Marin", "San Francisco", "San Mateo", "Santa Clara", "Solano"),
                               "Northern San Joaquin Valley" = c("Alpine", "Amador", "Calaveras", "Madera", "Mariposa", "Merced", "Mono", "San Joaquin", "Stanislaus", "Tuolumne"),
                               "Central Coast" = c("Monterey", "San Benito", "San Luis Obispo", "Santa Barbara", "Santa Cruz", "Ventura"),
                               "Southern San Joaquin Valley" = c("Fresno", "Inyo", "Kern", "Kings", "Tulare"),
                               "Inland Empire" = c("Riverside", "San Bernardino"),
                               "Los Angeles County" = c("Los Angeles"),
                               "Orange County" = c("Orange"),
                               "San Diego-Imperial" = c("San Diego", "Imperial")))

```

-   date (example must use functions from **lubridate**)

Lab 5 (revised to include all the suspect information and left join with interviews to see if the final suspect had any additional clues. Also revised to convert the date to a date object and create new variables for the month and year of the date using lubridate functions, and then filter the data based on these new date variables)

```{r}
#| label: wd-4-date

drivers_license |>
  rename(license_id = id) |>
  filter(gender == "female",
         hair_color == "red",
         car_make == "Tesla",
         car_model == "Model S",
         height >= 65,
         height <= 67) |>
  inner_join(person, by = "license_id") |>
  inner_join(facebook_event_checkin, by = join_by(id == person_id)) |>
  mutate(date = ymd(date),
         year = year(date),
         month = month(date)) |>
  filter(event_name == "SQL Symphony Concert",
         year == 2017,
         month == 12) |>
  group_by(name) |>
  filter(n() == 3) |>
  distinct(name, .keep_all = TRUE) |>
  left_join(interview, by = join_by(id == person_id)) |>
  select(name, id, transcript)

```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

Lab 5 (revised to include all the suspect information and left join with interviews to see if the final suspect had any additional clues. Left join is necessary here because we're only **adding** the interview information and don't want to remove the suspect if they don't have an interview)

```{r}
#| label: wd-5-left

drivers_license |>
  rename(license_id = id) |>
  filter(gender == "female",
         hair_color == "red",
         car_make == "Tesla",
         car_model == "Model S",
         height >= 65,
         height <= 67) |>
  inner_join(person, by = "license_id") |>
  inner_join(facebook_event_checkin, by = join_by(id == person_id)) |>
  filter(event_name == "SQL Symphony Concert",
         str_detect(date, "^201712")) |>
  group_by(name) |>
  filter(n() == 3) |>
  distinct(name, .keep_all = TRUE) |>
  left_join(interview, by = join_by(id == person_id)) |>
  select(name, id, transcript)

```

-   `right_join()`

Lab 5 (revised to include all the suspect information and left join with interviews to see if the final suspect had any additional clues. Right join is necessary here because we're only **adding** the interview information and don't want to remove the suspect if they don't have an interview. Because the suspect information is what we want to add too and it requires a lot of transformations/filters, I used an intermediate variable so that it's clearer to the reads what's being joined, as opposed to a nested pipeline)

```{r}
#| label: wd-5-right

suspect <- drivers_license |>
  rename(license_id = id) |>
  filter(gender == "female",
         hair_color == "red",
         car_make == "Tesla",
         car_model == "Model S",
         height >= 65,
         height <= 67) |>
  inner_join(person, by = "license_id") |>
  inner_join(facebook_event_checkin, by = join_by(id == person_id)) |>
  filter(event_name == "SQL Symphony Concert",
         str_detect(date, "^201712")) |>
  group_by(name) |>
  filter(n() == 3) |>
  distinct(name, .keep_all = TRUE)

interview |>
  right_join(suspect, by = join_by(person_id == id)) |>
  select(name, person_id, transcript)

```

-   `inner_join()`

Lab 5

```{r}
#| label: wd-5-inner

person |>
  filter(address_street_name == "Northwestern Dr") |>
  filter(address_number == max(address_number)) |>
  inner_join(interview, by = join_by(id == person_id)) |>
  pull(transcript)

```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

Lab 3 Question 12 (Revised to filter for instructors by semi-joining with instructors with doctorate or professor degrees, which will keep them and filter out instructors with masters degrees or no degree)

```{r}
#| label: wd-6-semi

library(knitr)
library(kableExtra)

included_teachers <- teacher_evals_clean |>
  filter(academic_degree %in% c("dr", "prof")) |>
  select(teacher_id)


teacher_evals_clean |>
  semi_join(included_teachers, by = "teacher_id") |>
  filter(sex == "female") |>
  group_by(teacher_id) |>
  summarise(avg_resp = mean(resp_share)) |>
  filter(avg_resp == max(avg_resp) | avg_resp == min(avg_resp)) |>
  kable() |>
  kable_styling()

```

-   `anti_join()`

Lab 3 Question 12 (Revised to filter for instructors with doctorate or professor degree by filtering out instructors with masters or no degree using an anti_join())

```{r}
#| label: wd-6-anti

library(knitr)
library(kableExtra)

excluded_teachers <- teacher_evals_clean |>
  filter(academic_degree %in% c("ma", "no_dgr")) |>
  select(teacher_id)


teacher_evals_clean |>
  anti_join(excluded_teachers, by = "teacher_id") |>
  filter(sex == "female") |>
  group_by(teacher_id) |>
  summarise(avg_resp = mean(resp_share)) |>
  filter(avg_resp == max(avg_resp) | avg_resp == min(avg_resp)) |>
  kable() |>
  kable_styling()


```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

Lab 4 Question 6 (revised to use if_all() instead of repeating !is.na(.) for each column. First revised with across() but changed to if_all() after seeing using across() in a filter() is superseded in Discord)

```{r}
#| label: wd-7-long

ca_childcare |>
  filter(if_all(c(mc_infant, mc_toddler, mc_preschool), ~ !is.na(.))) |>
  pivot_longer(cols = c(mc_infant,
                        mc_toddler,
                        mc_preschool),
               names_to = "age_class",
               values_to = "weekly_price") |>
  mutate(age_class = factor(age_class,
                            levels = c("mc_infant", "mc_toddler", "mc_preschool"),
                            labels = c("Infant", "Toddler", "Preschool")),
         region = factor(region)) |>
  ggplot(mapping = aes(x = study_year,
                       y = weekly_price,
                       color = fct_reorder2(.f = region,
                                            .x = study_year,
                                            .y = weekly_price
                       ))) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess") +
  facet_wrap(~age_class) +
  scale_x_continuous(breaks = seq(2008,
                                  2018,
                                  by = 2)) +
  scale_y_continuous(limits = c(100, 500)) +
  theme(aspect.ratio = 1,
        axis.text = element_text(size = 6),
  ) +
  labs(x = "Study Year",
       y = "",
       subtitle = "Weekly Median Price for Center-Based Childcare ($)",
       color = "California Region")

```

-   `pivot_wider()`

Lab 4 Question 4 (Revised to add kable styling ref: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html)

```{r}
#| label: wd-7-wide

ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarise(median_income = median(mhi_2018, na.rm = TRUE), .groups = 'drop') |>
  pivot_wider(names_from = study_year,
              values_from = median_income,
              names_prefix = "median_income_") |>
  arrange(desc(median_income_2018)) |>
  kable() |>
  kable_styling()

```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments:

Lab 2

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

Lab 4 Question 6

```{r}
#| label: r-2-1

ca_childcare |>
  filter(!is.na(mc_infant),
         !is.na(mc_toddler),
         !is.na(mc_preschool)) |>
  pivot_longer(cols = c(mc_infant,
                        mc_toddler,
                        mc_preschool),
               names_to = "age_class",
               values_to = "weekly_price") |>
  mutate(age_class = factor(age_class,
                            levels = c("mc_infant", "mc_toddler", "mc_preschool"),
                            labels = c("Infant", "Toddler", "Preschool")),
         region = factor(region)) |>
  ggplot(mapping = aes(x = study_year,
                       y = weekly_price,
                       color = fct_reorder2(.f = region,
                                            .x = study_year,
                                            .y = weekly_price
                       ))) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess") +
  facet_wrap(~age_class) +
  scale_x_continuous(breaks = seq(2008,
                                  2018,
                                  by = 2)) +
  scale_y_continuous(limits = c(100, 500)) +
  theme(aspect.ratio = 1,
        axis.text = element_text(size = 6),
  ) +
  labs(x = "Study Year",
       y = "",
       subtitle = "Weekly Median Price for Center-Based Childcare ($)",
       color = "California Region")


```

-   Example of **dplyr** pipeline

Lab 3 Question 10

```{r}
#| label: r-2-2

teacher_evals_clean |>
  group_by(teacher_id) |>
  filter(question_no == 901) |>
  summarise(avg = mean(SET_score_avg)) |>
  filter(avg == max(avg) | avg == min(avg))

```

-   Example of function formatting

Lab 3 Questions 10-12 (Questions 10, 11, and 12 all involve filtering to find instructors with the highest and lowest means for a specific variable, ex: % students failing in the current semester across all courses. I revised to abstract this duplicated logic into a function called filter_highest_lowest)

```{r}
#| label: r-2-3

filter_highest_lowest <- function(df, col){
  return(df |>
    summarise(avg = mean({{ col }})) |>
    filter(avg == max(avg) | avg == min(avg)))
}

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example -- any context

Lab 4 Question 5

```{r}
#| label: r-3-example

ca_childcare |>
  filter(study_year == 2018) |>
  group_by(region) |>
  summarise(median_mc_infant = median(mc_infant, na.rm = TRUE)) |>
  slice_min(order_by = median_mc_infant,
            n = 1)

```

-   Example of function stops

Lab 5 (I couldn't find a good spot to write a function that operates on vectors so I created another function that operates on dataframes. Getting the transcript was a common step in the investigation, so I wrote a function to accept a dataframe and get the transcripts for the the people in it. For the final suspect, we need to check if there are any more clues, so I modified get_transcript() to accept a boolean keep_na which will do a left join instead of an inner join so the function supports cases where we want to get the transcript even if it's NA)

```{r}
#| label: r-3-function-stops

get_transcript <- function(df, keep_na) {
  stopifnot(is.logical(keep_na))
  
  if (keep_na) {
    return(df |>
             left_join(interview, by = "person_id") |>
             pull(transcript))
  } else {
    return(df |>
             inner_join(interview, by = "person_id") |>
             pull(transcript))
  }
}

#Usage example:
#get_fit_now_member |>
#  filter(membership_status == "gold",
#         str_detect(id, "^48Z")) |>
#  inner_join(get_fit_now_check_in, join_by(id == membership_id)) |>
#  filter(check_in_date == '20180109') |>
#  inner_join(person, join_by(person_id == id, name)) |>
#  inner_join(drivers_license, by = join_by(license_id == id)) |>
#  filter(str_detect(plate_number, "H42W")) |>
#  get_transcript(keep_na = FALSE)

```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   at least two numeric variables

Lab 2 Question 4

```{r}
#| label: dvs-1-num

ggplot(data = surveys,
       mapping = aes(x = weight, y = hindfoot_length)) +
  facet_wrap(~species) + 
  geom_point(alpha = 0.2) + 
  labs(x = "weight (grams)",
       y = " ",
       title = "Relationship between weight and hindfoot length of rodents",
       subtitle = "hindfoot_length (mm)"
       )


```

-   at least one numeric variable and one categorical variable

Challenge 2, Spicy

```{r}
#| label: dvs-2-num-cat

ggplot(data = surveys,
       mapping = aes(x = weight, y = species, fill = genus)) +
  geom_jitter(alpha = 0.1, color = "steelblue") +
  geom_boxplot(outliers = FALSE) +
  labs(x = "Weight of Rodent (grams)",
       y = "",
       title = "Distribution of Weight Within Rodent Species",
       subtitle = "Species of Rodent",
       ) +
# ref 4
  scale_fill_brewer(palette = "Pastel2")

```

-   at least two categorical variables

Challenge 3, Question 2

```{r}
#| label: dvs-2-cat

ggplot(data = teacher_evals_compare,
       mapping = aes(x = sen_level,
                     fill = SET_level)
       ) +
  geom_bar( position = "stack") +
  scale_fill_manual(
    values = c("steelblue", "orange3")
  ) +
  labs(
    x = "Seniority of Instructor",
    y = "",
    subtitle = "Number of Sections"
  )

```

-   dates (timeseries plot)

Lab 4 Question 6

```{r}
#| label: dvs-2-date

ca_childcare |>
  filter(!is.na(mc_infant),
         !is.na(mc_toddler),
         !is.na(mc_preschool)) |>
  pivot_longer(cols = c(mc_infant,
                        mc_toddler,
                        mc_preschool),
               names_to = "age_class",
               values_to = "weekly_price") |>
  mutate(age_class = factor(age_class,
                            levels = c("mc_infant", "mc_toddler", "mc_preschool"),
                            labels = c("Infant", "Toddler", "Preschool")),
         region = factor(region)) |>
  ggplot(mapping = aes(x = study_year,
                       y = weekly_price,
                       color = fct_reorder2(.f = region,
                                            .x = study_year,
                                            .y = weekly_price
                       ))) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess") +
  facet_wrap(~age_class) +
  scale_x_continuous(breaks = seq(2008,
                                  2018,
                                  by = 2)) +
  scale_y_continuous(limits = c(100, 500)) +
  theme(aspect.ratio = 1,
        axis.text = element_text(size = 6),
  ) +
  labs(x = "Study Year",
       y = "",
       subtitle = "Weekly Median Price for Center-Based Childcare ($)",
       color = "California Region")

```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can ensure people don't tilt their head

Challenge 2, Spicy

```{r}
#| label: dvs-2-1

ggplot(data = surveys,
       mapping = aes(x = weight, y = species, fill = genus)) +
  geom_jitter(alpha = 0.1, color = "steelblue") +
  geom_boxplot(outliers = FALSE) +
  labs(x = "Weight of Rodent (grams)",
       y = "",
       title = "Distribution of Weight Within Rodent Species",
       subtitle = "Species of Rodent",
       ) +
# ref 4
  scale_fill_brewer(palette = "Pastel2")

```

-   I can modify the text in my plot to be more readable

Lab 4 Question 6 (Revised to include dollar signs next to the weekly price on the y axis. Ref: https://scales.r-lib.org/reference/label_dollar.html. label_dollar() is necessary because we are scaling the y axis so if I added $ sign to weekly_price earlier with dollar() I would get in error in scale_y_continuous())

```{r}
#| label: dvs-2-2

ca_childcare |>
  filter(if_all(c(mc_infant, mc_toddler, mc_preschool), ~ !is.na(.))) |>
  pivot_longer(cols = c(mc_infant,
                        mc_toddler,
                        mc_preschool),
               names_to = "age_class",
               values_to = "weekly_price") |>
  mutate(age_class = factor(age_class,
                            levels = c("mc_infant", "mc_toddler", "mc_preschool"),
                            labels = c("Infant", "Toddler", "Preschool")),
         region = factor(region)) |>
  ggplot(mapping = aes(x = study_year,
                       y = weekly_price,
                       color = fct_reorder2(.f = region,
                                            .x = study_year,
                                            .y = weekly_price
                       ))) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess") +
  facet_wrap(~age_class) +
  scale_x_continuous(breaks = seq(2008,
                                  2018,
                                  by = 2)) +
  scale_y_continuous(labels = label_dollar(),
                     limits = c(100, 500)) +
  theme(aspect.ratio = 1,
        axis.text = element_text(size = 6)
  ) +
  labs(x = "Study Year",
       y = "",
       subtitle = "Weekly Median Price for Center-Based Childcare",
       color = "California Region")

```

-   I can reorder my legend to align with the colors in my plot

Lab 4 Question 6

```{r}
#| label: dvs-2-3

ca_childcare |>
  filter(!is.na(mc_infant),
         !is.na(mc_toddler),
         !is.na(mc_preschool)) |>
  pivot_longer(cols = c(mc_infant,
                        mc_toddler,
                        mc_preschool),
               names_to = "age_class",
               values_to = "weekly_price") |>
  mutate(age_class = factor(age_class,
                            levels = c("mc_infant", "mc_toddler", "mc_preschool"),
                            labels = c("Infant", "Toddler", "Preschool")),
         region = factor(region)) |>
  ggplot(mapping = aes(x = study_year,
                       y = weekly_price,
                       color = fct_reorder2(.f = region,
                                            .x = study_year,
                                            .y = weekly_price
                       ))) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess") +
  facet_wrap(~age_class) +
  scale_x_continuous(breaks = seq(2008,
                                  2018,
                                  by = 2)) +
  scale_y_continuous(limits = c(100, 500)) +
  theme(aspect.ratio = 1,
        axis.text = element_text(size = 6),
  ) +
  labs(x = "Study Year",
       y = "",
       subtitle = "Weekly Median Price for Center-Based Childcare ($)",
       color = "California Region")

```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors

Challenge 2, Spicy

```{r}
#| label: dvs-3-1

ggplot(data = surveys,
       mapping = aes(x = weight, y = species, fill = genus)) +
  geom_jitter(alpha = 0.1, color = "steelblue") +
  geom_boxplot(outliers = FALSE) +
  labs(x = "Weight of Rodent (grams)",
       y = "",
       title = "Distribution of Weight Within Rodent Species",
       subtitle = "Species of Rodent",
       ) +
# ref 4
  scale_fill_brewer(palette = "Pastel2")

```

-   I can use annotations

Challenge 2 (revised to add the mean weights of each species as text on the graph to make it easier to see which species have the biggest rodents.
ref1: https://ggplot2.tidyverse.org/reference/geom_text.html)

```{r}
#| label: dvs-3-2

mean_weights <- surveys |>
  group_by(species, genus) |>
  summarise(mean_weight = mean(weight, na.rm = TRUE), .groups = 'drop')

surveys |> ggplot(aes(x = weight, y = species, fill = genus)) +
  geom_jitter(alpha = 0.1, color = "steelblue") +
  geom_boxplot(outliers = FALSE) +
  geom_text(
    data = mean_weights,
    aes(x = mean_weight, y = species, label = round(mean_weight, 1)),
    color = "black",
    size = 3,
    fontface = "bold",
    vjust = 2
  ) +
  labs(
    x = "Weight of Rodent (grams)",
    y = "",
    title = "Distribution of Weight Within Rodent Species",
    subtitle = "Species of Rodent"
  ) +
  scale_fill_brewer(palette = "Pastel2")

```

-   I can be creative...

Lab 1 Question 6 (Revised to look better than the bare boxplot. Added dark theme, custom colors, changed the font to Georgia, centered the title, added labels that don't require head-tilting and changed the font sizes to look better)

```{r}
#| label: dvs-3-3

ggplot(data = ToothGrowth, 
       mapping = aes(x = supp, y = len, fill = supp)) + 
  geom_boxplot() +
  labs(
    x = "Supplement Type", 
    y = "", 
    title = "Guinea Pig Teeth Growth by Vitamin C Delivery Method",
    subtitle = "Length of Teeth (mm)"
  ) +
  scale_fill_brewer(palette = "Pastel2") +
  theme_dark() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold", family = "Georgia"),
    plot.subtitle = element_text(size = 12, family = "Georgia"),
    axis.title = element_text(size = 12, family = "Georgia"),
    axis.text = element_text(size = 10, family = "Georgia")
  )

```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

Lab 3 Question 6

```{r}
#| label: dvs-4-summarize

teacher_evals_clean |>
  summarise(instructors = n_distinct(teacher_id),
            courses = n_distinct(course_id))

```

-   Example using `across()`

Lab 3 Question 6 (Revised to use across() to find distinct values. This makes the code more scalable if I wanted to find the number of unique values for other variables too, as I could just add to .cols and not have to specify n_distinct for every new column.)

```{r}
#| label: dvs-4-across

teacher_evals_clean |>
  summarise(across(.cols = c(teacher_id, course_id), 
                   .fns = n_distinct, 
                   .names = "Unique {.col}s"))

```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

Lab 4 Question 4 (Revised to add kable styling ref: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html)

```{r}
#| label: dvs-5-1

ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarise(median_income = median(mhi_2018, na.rm = TRUE), .groups = 'drop') |>
  pivot_wider(names_from = study_year,
              values_from = median_income,
              names_prefix = "median_income_") |>
  arrange(desc(median_income_2018)) |>
  kable() |>
  kable_styling()

```

-   Example 2

Lab 3 Question 12 (Revised to add kable styling ref: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html)

```{r}
#| label: dvs-5-2

teacher_evals_clean |>
  filter(academic_degree %in% c("dr", "prof"),
         sex == "female") |>
  group_by(teacher_id) |>
  summarise(avg_resp = mean(resp_share)) |>
  filter(avg_resp == max(avg_resp) | avg_resp == min(avg_resp)) |>
  kable() |>
  kable_styling()

```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

Lab 4 Question 4 (Revised to add kable styling ref: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html)

```{r}
#| label: dvs-6-1

ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarise(median_income = median(mhi_2018, na.rm = TRUE), .groups = 'drop') |>
  pivot_wider(names_from = study_year,
              values_from = median_income,
              names_prefix = "median_income_") |>
  arrange(desc(median_income_2018)) |>
  kable() |>
  kable_styling()

```

-   Example 2

Lab 3, Question 8 (Revised to add kable styling ref: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html)

```{r}
#| label: dvs-6-2

teacher_evals_clean|>
  distinct(teacher_id, .keep_all = TRUE) |>
  group_by(academic_degree, sex) |>
  summarise(
    avg_seniority = mean(seniority),
    total_instructors = n_distinct(teacher_id)
  ) |>
  kable() |>
  kable_styling()

```

**DVS-7: I show creativity in my tables.**

-   Example 1

Lab 3, Question 8 (Revised to add kable styling ref1: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html
ref2: https://www.rdocumentation.org/packages/kableExtra/versions/1.4.0/topics/kable_styling)


```{r}
#| label: dvs-7-1

teacher_evals_clean|>
  distinct(teacher_id, .keep_all = TRUE) |>
  group_by(academic_degree, sex) |>
  summarise(
    avg_seniority = mean(seniority),
    total_instructors = n_distinct(teacher_id)
  ) |>
  kable() |>
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("striped", "hover", "condensed")
  )

```

-   Example 2

Lab 4 Question 4 (Revised to add kable styling ref1: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html
ref2: https://www.rdocumentation.org/packages/kableExtra/versions/1.4.0/topics/kable_styling)

```{r}
#| label: dvs-7-2

ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(region, study_year) |>
  summarise(median_income = median(mhi_2018, na.rm = TRUE), .groups = 'drop') |>
  pivot_wider(names_from = study_year,
              values_from = median_income,
              names_prefix = "median_income_") |>
  arrange(desc(median_income_2018)) |>
  kable() |>
  kable_styling(
    htmltable_class = "lightable-material",
    html_font = "Arial Narrow"
  )

```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

Lab 5

```{r}
#| label: pe-1-one-call

get_fit_now_member |>
  filter(membership_status == "gold",
         str_detect(id, "^48Z")) |>
  inner_join(get_fit_now_check_in, join_by(id == membership_id)) |>
  filter(check_in_date == '20180109') |>
  inner_join(person, join_by(person_id == id, name)) |>
  inner_join(drivers_license, by = join_by(license_id == id)) |>
  filter(str_detect(plate_number, "H42W")) |>
  select(person_id, name)

```

-   `across()`

Lab 3 Question 6 (Revised to use across() to find distinct values. This makes the code more scalable if I wanted to find the number of unique values for other variables too, as I could just add to .cols and not have to specify n_distinct for every new column)

```{r}
#| label: pe-1-across

teacher_evals_clean |>
  summarise(across(.cols = c(teacher_id, course_id), 
                   .fns = n_distinct, 
                   .names = "Unique {.col}s"))

```

-   `map()` functions

Lab 8 Question 1 (Revised to add kable styling ref: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html)

```{r}
#| label: pe-1-map-1

surveys |>
  map_chr(typeof) |>
  data.frame() |>
  rownames_to_column() |>
  setNames(c("variable", "type")) |>
  pivot_wider(names_from = variable,
              values_from = type) |>
  kable() |>
  kable_styling()

# ref: https://www.geeksforgeeks.org/convert-row-names-into-column-of-dataframe-in-r/
# ref: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/setNames

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Function that operates on vectors

Lab 5 (I couldn't find a good spot to write a function that operates on vectors so I created another function that operates on dataframes. Getting the transcript was a common step in the investigation, so I wrote a function to accept a dataframe and get the transcripts for the the people in it. For the final suspect, we need to check if there are any more clues, so I modified get_transcript() to accept a boolean keep_na which will do a left join instead of an inner join so the function supports cases where we want to get the transcript even if it's NA)

```{r}
#| label: pe-2-1

get_transcript <- function(df, keep_na) {
  stopifnot(is.logical(keep_na))
  
  if (keep_na) {
    return(df |>
             left_join(interview, by = "person_id") |>
             pull(transcript))
  } else {
    return(df |>
             inner_join(interview, by = "person_id") |>
             pull(transcript))
  }
}

#Usage example:
#get_fit_now_member |>
#  filter(membership_status == "gold",
#         str_detect(id, "^48Z")) |>
#  inner_join(get_fit_now_check_in, join_by(id == membership_id)) |>
#  filter(check_in_date == '20180109') |>
#  inner_join(person, join_by(person_id == id, name)) |>
#  inner_join(drivers_license, by = join_by(license_id == id)) |>
#  filter(str_detect(plate_number, "H42W")) |>
#  get_transcript(keep_na = FALSE)

```

-   Function that operates on data frames

Lab 3 Questions 10-12 (Questions 10, 11, and 12 all involve filtering to find instructors with the highest and lowest means for a specific variable, ex: % students failing in the current semester across all courses. I revised to abstract this duplicated logic into a function called filter_highest_lowest. This function makes it easy to analyze the highest and lowest performance of any group of instructors across any quantitative variable in the dataset, and can be directly included in transformations without intermediate variables since a dataframe is the first argument to the function)

```{r}
#| label: pe-2-2

filter_highest_lowest <- function(df, col){
  return(df |>
    summarise(avg = mean({{ col }})) |>
    filter(avg == max(avg) | avg == min(avg)))
}

# Usage example, Lab 3 Question 10
#teacher_evals_clean |>
#  group_by(teacher_id) |>
#  filter(question_no == 901) |>
#  filter_highest_lowest(SET_score_avg)

```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`

Lab 3 Question 6 (Revised to use across() to find distinct values. This makes the code more scalable if I wanted to find the number of unique values for other variables too, as I could just add to .cols and not have to specify n_distinct for every new column)

```{r}
#| label: pe-3-across

teacher_evals_clean |>
  summarise(across(.cols = c(teacher_id, course_id), 
                   .fns = n_distinct, 
                   .names = "Unique {.col}s"))

```

-   `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

Lab 8 Question 1 (Revised to add kable styling ref: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html)

```{r}
#| label: pe-3-map-1

surveys |>
  map_chr(typeof) |>
  data.frame() |>
  rownames_to_column() |>
  setNames(c("variable", "type")) |>
  pivot_wider(names_from = variable,
              values_from = type) |>
  kable() |>
  kable_styling()

# ref: https://www.geeksforgeeks.org/convert-row-names-into-column-of-dataframe-in-r/
# ref: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/setNames

```

-   `map()` function with **more than one** input (e.g., `map_2()` or `pmap()`)

Lab 2 Question 18 (Revised to simulate 1000 random rodent weights following normal distribution using the mean and sd for each species and plotted along with mean to further reject the conclusion that the mean weight is the same for all 14 rodent species)

```{r}
#| label: pe-3-map-2

simulate_data <- function(mean, sd){
  stopifnot(is.numeric(mean), is.numeric(sd))
  return(rnorm(n = 1000, mean = mean, sd = sd))
}

surveys |>
  group_by(species) |>
  summarise(
    mean_weight = mean(weight, na.rm = TRUE),
    sd_weight = sd(weight, na.rm = TRUE),
    .groups = "drop"
  ) |>
  mutate(simulated_weights = map2(
    .x = mean_weight,
    .y = sd_weight,
    .f = simulate_data
  )) |>
  unnest(cols = simulated_weights) |>
  ggplot(mapping = aes(x = simulated_weights)) +
  geom_density(alpha = 0.3, fill = "steelblue") +
  geom_vline(mapping = aes(xintercept = mean_weight),
             linetype = "dashed",
             color = "red") +
  facet_wrap(~ species, scales = "free_y") +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    strip.text = element_text(face = "bold", size = 9)
  ) +
  labs(title = "Distribution of Simulated Weights for Rodent Weight",
       x = "Simulated Weight",
       y = "",
       subtitle = "Density")

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

Lab 3 Question 7

```{r}
#| label: pe-4-1

teacher_evals_clean |>
  filter(if_any(.cols = everything(),
                .fns = ~ is.na(.x)))

```

-   I can connect a data wrangling pipeline into a `ggplot()`

Lab 4 Question 6

```{r}
#| label: pe-4-2


ca_childcare |>
  filter(!is.na(mc_infant),
         !is.na(mc_toddler),
         !is.na(mc_preschool)) |>
  pivot_longer(cols = c(mc_infant,
                        mc_toddler,
                        mc_preschool),
               names_to = "age_class",
               values_to = "weekly_price") |>
  mutate(age_class = factor(age_class,
                            levels = c("mc_infant", "mc_toddler", "mc_preschool"),
                            labels = c("Infant", "Toddler", "Preschool")),
         region = factor(region)) |>
  ggplot(mapping = aes(x = study_year,
                       y = weekly_price,
                       color = fct_reorder2(.f = region,
                                            .x = study_year,
                                            .y = weekly_price
                       ))) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess") +
  facet_wrap(~age_class) +
  scale_x_continuous(breaks = seq(2008,
                                  2018,
                                  by = 2)) +
  scale_y_continuous(limits = c(100, 500)) +
  theme(aspect.ratio = 1,
        axis.text = element_text(size = 6),
  ) +
  labs(x = "Study Year",
       y = "",
       subtitle = "Weekly Median Price for Center-Based Childcare ($)",
       color = "California Region")

```

## Data Simulation & Statisical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

Lab 2 Question 18 (Revised to simulate 1000 random rodent weights following normal distribution using the mean and sd for each species and plotted along with mean to further reject the conclusion that the mean weight is the same for all 14 rodent species)

```{r}
#| label: dsm-1-1

simulate_data <- function(mean, sd){
  stopifnot(is.numeric(mean), is.numeric(sd))
  return(rnorm(n = 1000, mean = mean, sd = sd))
}

surveys |>
  group_by(species) |>
  summarise(
    mean_weight = mean(weight, na.rm = TRUE),
    sd_weight = sd(weight, na.rm = TRUE),
    .groups = "drop"
  ) |>
  mutate(simulated_weights = map2(
    .x = mean_weight,
    .y = sd_weight,
    .f = simulate_data
  )) |>
  unnest(cols = simulated_weights) |>
  ggplot(mapping = aes(x = simulated_weights)) +
  geom_density(alpha = 0.3, fill = "steelblue") +
  geom_vline(mapping = aes(xintercept = mean_weight),
             linetype = "dashed",
             color = "red") +
  facet_wrap(~ species, scales = "free_y") +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    strip.text = element_text(face = "bold", size = 9)
  ) +
  labs(title = "Distribution of Simulated Weights for Rodent Weight",
       x = "Simulated Weight",
       y = "",
       subtitle = "Density")
  

```

-   Example 2

Lab 3 (Couldn't find any other previous labs where simulating data would help answer questions so I simulated 1000 more teacher eval entries using rnorm for SET_score_avg and stud_grade_avg, runif for resp_share, and sampling random integers for teacher_id)

```{r}
#| label: dsm-1-2

# get min, max, mean, and sd for numeric variables
teacher_evals |>
  summarise(across(where(is.numeric), 
                   list(min = ~min(., na.rm = TRUE), 
                        max = ~max(., na.rm = TRUE), 
                        mean = ~mean(., na.rm = TRUE), 
                        sd = ~sd(., na.rm = TRUE)
                        ),
                    .names = "{col}_values_{fn}"
                   )) |>
   pivot_longer(
    cols = everything(),
    names_to = c("variable", "statistic"),
    names_sep = "_values_",
    values_to = "value"
  ) |>
  pivot_wider(
    names_from = "statistic",
    values_from = "value"
  )

# simulate teacher eval
simulated_teacher_evals <- tibble(
  # ref: https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/sample, not runif bc not continuous
  teacher_id = sample(3432:110292, 1000, replace = TRUE),
  SET_score_avg = rnorm(n = 1000, mean = 4.39, sd = 0.83),
  resp_share = runif(n = 1000, min = 0.0035, max = 1),
  stud_grade_avg = rnorm(n = 1000, mean = 3.96, sd = 0.55)
)

```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

Challenge 3 Question 3

```{r}
#| label: dsm-2-1

chisq.test(
  x = teacher_evals_compare$SET_level,
  y = teacher_evals_compare$sen_level
)

```

-   Example 2

Lab 2 Question 17

```{r}
#| label: dsm-2-2

species_mod <- aov(weight ~ species, data = surveys)

summary(species_mod)

```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

I revised my thinking by taking careful note of the feedback I received and resubmitting the questions where I had demonstrated a lack of full
understanding (as opposed to forgetting a space or newline). For example, in lab 3 I used unnecessary intermediate variables for the min and
max values towards the end, and revised those to use a single pipeline. I then applied this change in my future work, and have made an
intentional effort not to use any intermediate variables since. In this way, I feel my code quality has steadily increased throughout the
assignments, as shown in the code I've provided in the portfolio. However, I've also learned about when intermediate variables are appropriate,
like if they can be used to avoid nested pipelines like in my right_join() in WD-5. The goal is always to write readable and efficient code,
and over the course I've revised my thinking to appropriately use (or not use) intermediate variables to do this.

<!-- For the revisions included in your Portfolio, to help me understand the nature of your revisions, please denote somehow the feedback I provided you (e.g., boldface, italics, colored text) before your revisions. -->

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

I've extended my thinking by taking on the challenge activities, and consistently aiming for above just the bare minimum (not just picking the
easiest challenge available). I used code chunks from these challenges for my portfolio, because I feel that the times I challenged myself
resulted in better and more sophisticated code than the code in the labs and practice activities. Additionally, in DVS-7 I extended my thinking
by looking through the kable_styling() documentation to figure out how to add interactive aspects like hovering to my tables. Creating the
tables for DVS-7 required learning more about how the HTML is rendered, because not all the options are available for HTML (like changing
stripe color for alternating stripes).

## Peer Support & Collaboration

<!-- Include an image or a description of feedback you gave that you are proud of (either in a peer review or in Discord). -->

Here is some feedback I gave a classmate on Lab 5 for their code efficiency that I am proud of:

Some suggestions I have would be to use stringr functions like str_detect to find Annabel Miller instead of printing out all of the people and
finding her manually. Also, although the right, left, and full joins work, the inner joins might be more suitable for this use case and filter
out more of the unwanted data (rows with NA values in last step). Lastly, for join conditions like by = join_by(person_id == person_id), you
should just be able to do by = "person_id" which reads a little easier. Overall nice work! Looks like you were able to get hte right answer
pretty efficiently.


<!-- Include a description of how you grew as a collaborator through the weekly pair programming activities.   -->

During the weekly pair programming activities I improved on my ability to make sure both me and my partner understood each question and
solution that we worked on. Because we switched back and forth between coding and developing, even if my partner or I had previously vocalized
that a concept made sense, it was always very clear when we had an incomplete understanding. The pair programming activities bettered my
ability to gauge my partners level of understanding, and also made it clear to me how important it is to only move on once both me and my
partner fully understand what's going on. Additionally, having to articulate my thought processes without demonstrating or showing what I meant
has forced me to improve the clarity of my explanations and be more patient.
